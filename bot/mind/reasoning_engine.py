"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
LEGENDARY AGENT - Reasoning Engine
Ù…Ø­Ø±Ùƒ Ø§Ù„ØªÙÙƒÙŠØ± Ø§Ù„Ù…Ù†Ø·Ù‚ÙŠ
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import numpy as np
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from loguru import logger


class ReasoningType(Enum):
    """Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„ØªÙÙƒÙŠØ±"""
    DEDUCTIVE = "Ø§Ø³ØªÙ†ØªØ§Ø¬ÙŠ"      # Ù…Ù† Ø§Ù„Ø¹Ø§Ù… Ù„Ù„Ø®Ø§Øµ
    INDUCTIVE = "Ø§Ø³ØªÙ‚Ø±Ø§Ø¦ÙŠ"       # Ù…Ù† Ø§Ù„Ø®Ø§Øµ Ù„Ù„Ø¹Ø§Ù…
    ABDUCTIVE = "Ø§ÙØªØ±Ø§Ø¶ÙŠ"        # Ø£ÙØ¶Ù„ ØªÙØ³ÙŠØ±
    ANALOGICAL = "ØªØ´Ø§Ø¨Ù‡ÙŠ"        # Ø¨Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©
    CAUSAL = "Ø³Ø¨Ø¨ÙŠ"              # Ø§Ù„Ø³Ø¨Ø¨ ÙˆØ§Ù„Ù†ØªÙŠØ¬Ø©


@dataclass
class Premise:
    """Ù…Ù‚Ø¯Ù…Ø© Ù…Ù†Ø·Ù‚ÙŠØ©"""
    statement: str
    confidence: float
    source: str
    timestamp: datetime = field(default_factory=datetime.now)


@dataclass
class Conclusion:
    """Ø§Ø³ØªÙ†ØªØ§Ø¬ Ù…Ù†Ø·Ù‚ÙŠ"""
    statement: str
    confidence: float
    reasoning_type: ReasoningType
    premises: List[Premise]
    supporting_evidence: List[str]
    counter_evidence: List[str]
    timestamp: datetime = field(default_factory=datetime.now)


@dataclass
class Hypothesis:
    """ÙØ±Ø¶ÙŠØ©"""
    statement: str
    probability: float
    evidence_for: List[str]
    evidence_against: List[str]
    test_criteria: List[str]
    status: str = "pending"  # pending, confirmed, rejected


class ReasoningEngine:
    """
    Ù…Ø­Ø±Ùƒ Ø§Ù„ØªÙÙƒÙŠØ± Ø§Ù„Ù…Ù†Ø·Ù‚ÙŠ
    
    ÙŠÙ‚ÙˆÙ… Ø¨Ù€:
    - Ø§Ù„ØªÙÙƒÙŠØ± Ø§Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬ÙŠ ÙˆØ§Ù„Ø§Ø³ØªÙ‚Ø±Ø§Ø¦ÙŠ
    - ØªÙˆÙ„ÙŠØ¯ ÙˆØ§Ø®ØªØ¨Ø§Ø± Ø§Ù„ÙØ±Ø¶ÙŠØ§Øª
    - ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ø¨Ø¨ ÙˆØ§Ù„Ù†ØªÙŠØ¬Ø©
    - Ø§Ù„ØªØ¹Ù„Ù… Ù…Ù† Ø§Ù„Ø£Ù†Ù…Ø§Ø·
    """
    
    def __init__(self):
        """ØªÙ‡ÙŠØ¦Ø© Ù…Ø­Ø±Ùƒ Ø§Ù„ØªÙÙƒÙŠØ±"""
        self.premises: List[Premise] = []
        self.conclusions: List[Conclusion] = []
        self.hypotheses: List[Hypothesis] = []
        self.learned_patterns: Dict[str, Any] = {}
        self.reasoning_history: List[Dict] = []
        
        # Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„ØªÙÙƒÙŠØ± Ø§Ù„Ù…Ø¯Ù…Ø¬Ø©
        self._init_reasoning_rules()
        
        logger.info("ğŸ§  ReasoningEngine initialized")
    
    def _init_reasoning_rules(self):
        """ØªÙ‡ÙŠØ¦Ø© Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„ØªÙÙƒÙŠØ±"""
        self.rules = {
            # Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø³ÙˆÙ‚ Ø§Ù„ØµØ§Ø¹Ø¯
            'bullish_rules': [
                {
                    'conditions': ['rsi < 30', 'price_above_sma_200', 'volume_increasing'],
                    'conclusion': 'ÙØ±ØµØ© Ø´Ø±Ø§Ø¡ Ù‚ÙˆÙŠØ© - ØªØ´Ø¨Ø¹ Ø¨ÙŠØ¹ÙŠ Ù…Ø¹ Ø§ØªØ¬Ø§Ù‡ ØµØ§Ø¹Ø¯',
                    'confidence': 0.85
                },
                {
                    'conditions': ['macd_bullish_cross', 'adx > 25', 'price_above_ema_50'],
                    'conclusion': 'Ø¨Ø¯Ø§ÙŠØ© Ù…ÙˆØ¬Ø© ØµØ¹ÙˆØ¯ - ØªØ£ÙƒÙŠØ¯ Ø§Ù„Ø²Ø®Ù…',
                    'confidence': 0.80
                },
                {
                    'conditions': ['higher_highs', 'higher_lows', 'volume_confirmation'],
                    'conclusion': 'Ø§ØªØ¬Ø§Ù‡ ØµØ§Ø¹Ø¯ Ù…Ø¤ÙƒØ¯ - Ø§Ø³ØªÙ…Ø±Ø§Ø± Ù…ØªÙˆÙ‚Ø¹',
                    'confidence': 0.75
                }
            ],
            # Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø³ÙˆÙ‚ Ø§Ù„Ù‡Ø§Ø¨Ø·
            'bearish_rules': [
                {
                    'conditions': ['rsi > 70', 'price_below_sma_200', 'volume_decreasing'],
                    'conclusion': 'ÙØ±ØµØ© Ø¨ÙŠØ¹ Ù‚ÙˆÙŠØ© - ØªØ´Ø¨Ø¹ Ø´Ø±Ø§Ø¦ÙŠ Ù…Ø¹ Ø§ØªØ¬Ø§Ù‡ Ù‡Ø§Ø¨Ø·',
                    'confidence': 0.85
                },
                {
                    'conditions': ['macd_bearish_cross', 'adx > 25', 'price_below_ema_50'],
                    'conclusion': 'Ø¨Ø¯Ø§ÙŠØ© Ù…ÙˆØ¬Ø© Ù‡Ø¨ÙˆØ· - ØªØ£ÙƒÙŠØ¯ Ø§Ù„Ø¶Ø¹Ù',
                    'confidence': 0.80
                },
                {
                    'conditions': ['lower_highs', 'lower_lows', 'volume_confirmation'],
                    'conclusion': 'Ø§ØªØ¬Ø§Ù‡ Ù‡Ø§Ø¨Ø· Ù…Ø¤ÙƒØ¯ - Ø§Ø³ØªÙ…Ø±Ø§Ø± Ù…ØªÙˆÙ‚Ø¹',
                    'confidence': 0.75
                }
            ],
            # Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„ØªÙ‚Ù„Ø¨
            'volatility_rules': [
                {
                    'conditions': ['bb_squeeze', 'low_atr', 'consolidation'],
                    'conclusion': 'Ø§Ù†ÙØ¬Ø§Ø± Ø³Ø¹Ø±ÙŠ ÙˆØ´ÙŠÙƒ - Ø§Ø³ØªØ¹Ø¯ Ù„Ù„Ø­Ø±ÙƒØ©',
                    'confidence': 0.70
                },
                {
                    'conditions': ['high_atr', 'wide_bb', 'erratic_price'],
                    'conclusion': 'ØªÙ‚Ù„Ø¨ Ø¹Ø§Ù„ÙŠ - Ù‚Ù„Ù„ Ø­Ø¬Ù… Ø§Ù„ØµÙÙ‚Ø§Øª',
                    'confidence': 0.80
                }
            ],
            # Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø§Ù†Ø¹ÙƒØ§Ø³
            'reversal_rules': [
                {
                    'conditions': ['divergence_rsi', 'support_level', 'volume_spike'],
                    'conclusion': 'Ø§Ù†Ø¹ÙƒØ§Ø³ Ù…Ø­ØªÙ…Ù„ - Ø±Ø§Ù‚Ø¨ Ø§Ù„ØªØ£ÙƒÙŠØ¯',
                    'confidence': 0.65
                },
                {
                    'conditions': ['double_bottom', 'bullish_engulfing', 'volume_increase'],
                    'conclusion': 'Ø§Ù†Ø¹ÙƒØ§Ø³ ØµØ¹ÙˆØ¯ÙŠ Ù…Ø¤ÙƒØ¯',
                    'confidence': 0.75
                }
            ]
        }
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # DEDUCTIVE REASONING - Ø§Ù„ØªÙÙƒÙŠØ± Ø§Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬ÙŠ
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def deduce(
        self,
        premises: List[Premise],
        context: Dict[str, Any]
    ) -> Optional[Conclusion]:
        """
        Ø§Ù„ØªÙÙƒÙŠØ± Ø§Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬ÙŠ - Ù…Ù† Ø§Ù„Ø¹Ø§Ù… Ù„Ù„Ø®Ø§Øµ
        
        Args:
            premises: Ø§Ù„Ù…Ù‚Ø¯Ù…Ø§Øª
            context: Ø§Ù„Ø³ÙŠØ§Ù‚
            
        Returns:
            Ø§Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬
        """
        if not premises:
            return None
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù‚Ø§Ø¹Ø¯Ø© Ù…Ø·Ø§Ø¨Ù‚Ø©
        matched_rule = None
        max_match_score = 0
        
        for category, rules in self.rules.items():
            for rule in rules:
                match_score = self._calculate_rule_match(
                    rule['conditions'], 
                    premises, 
                    context
                )
                if match_score > max_match_score:
                    max_match_score = match_score
                    matched_rule = rule
        
        if matched_rule and max_match_score > 0.5:
            conclusion = Conclusion(
                statement=matched_rule['conclusion'],
                confidence=matched_rule['confidence'] * max_match_score,
                reasoning_type=ReasoningType.DEDUCTIVE,
                premises=premises,
                supporting_evidence=[p.statement for p in premises],
                counter_evidence=[]
            )
            
            self.conclusions.append(conclusion)
            self._log_reasoning('DEDUCTIVE', premises, conclusion)
            
            return conclusion
        
        return None
    
    def _calculate_rule_match(
        self,
        conditions: List[str],
        premises: List[Premise],
        context: Dict[str, Any]
    ) -> float:
        """Ø­Ø³Ø§Ø¨ Ø¯Ø±Ø¬Ø© ØªØ·Ø§Ø¨Ù‚ Ø§Ù„Ù‚Ø§Ø¹Ø¯Ø©"""
        if not conditions:
            return 0.0
        
        matched = 0
        premise_texts = [p.statement.lower() for p in premises]
        
        for condition in conditions:
            # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù…Ù‚Ø¯Ù…Ø§Øª
            for text in premise_texts:
                if condition.lower() in text or self._semantic_match(condition, text):
                    matched += 1
                    break
            else:
                # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ø³ÙŠØ§Ù‚
                if self._check_context_condition(condition, context):
                    matched += 1
        
        return matched / len(conditions)
    
    def _semantic_match(self, condition: str, text: str) -> bool:
        """ØªØ·Ø§Ø¨Ù‚ Ø¯Ù„Ø§Ù„ÙŠ Ø¨Ø³ÙŠØ·"""
        # ÙƒÙ„Ù…Ø§Øª Ù…ØªØ±Ø§Ø¯ÙØ©
        synonyms = {
            'bullish': ['ØµØ§Ø¹Ø¯', 'Ø¥ÙŠØ¬Ø§Ø¨ÙŠ', 'Ø´Ø±Ø§Ø¡', 'Ø§Ø±ØªÙØ§Ø¹'],
            'bearish': ['Ù‡Ø§Ø¨Ø·', 'Ø³Ù„Ø¨ÙŠ', 'Ø¨ÙŠØ¹', 'Ø§Ù†Ø®ÙØ§Ø¶'],
            'high': ['Ø¹Ø§Ù„ÙŠ', 'Ù…Ø±ØªÙØ¹', 'ÙƒØ¨ÙŠØ±'],
            'low': ['Ù…Ù†Ø®ÙØ¶', 'ØµØºÙŠØ±', 'Ø¶Ø¹ÙŠÙ'],
            'increasing': ['Ù…ØªØ²Ø§ÙŠØ¯', 'ÙŠØ±ØªÙØ¹', 'ÙŠÙ†Ù…Ùˆ'],
            'decreasing': ['Ù…ØªÙ†Ø§Ù‚Øµ', 'ÙŠÙ‡Ø¨Ø·', 'ÙŠÙ†Ø®ÙØ¶']
        }
        
        for key, values in synonyms.items():
            if key in condition.lower():
                for syn in values:
                    if syn in text:
                        return True
        
        return False
    
    def _check_context_condition(self, condition: str, context: Dict) -> bool:
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø´Ø±Ø· ÙÙŠ Ø§Ù„Ø³ÙŠØ§Ù‚"""
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ø±Ø·
        parts = condition.replace('_', ' ').split()
        
        for key, value in context.items():
            key_lower = key.lower()
            if any(p in key_lower for p in parts):
                if isinstance(value, bool):
                    return value
                elif isinstance(value, (int, float)):
                    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø´Ø±ÙˆØ· Ø§Ù„Ø±Ù‚Ù…ÙŠØ©
                    if '>' in condition:
                        threshold = float(condition.split('>')[-1].strip())
                        return value > threshold
                    elif '<' in condition:
                        threshold = float(condition.split('<')[-1].strip())
                        return value < threshold
        
        return False
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # INDUCTIVE REASONING - Ø§Ù„ØªÙÙƒÙŠØ± Ø§Ù„Ø§Ø³ØªÙ‚Ø±Ø§Ø¦ÙŠ
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def induce(
        self,
        observations: List[Dict[str, Any]],
        min_pattern_frequency: int = 3
    ) -> List[Dict[str, Any]]:
        """
        Ø§Ù„ØªÙÙƒÙŠØ± Ø§Ù„Ø§Ø³ØªÙ‚Ø±Ø§Ø¦ÙŠ - Ù…Ù† Ø§Ù„Ø®Ø§Øµ Ù„Ù„Ø¹Ø§Ù…
        Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ù…Ù† Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª
        
        Args:
            observations: Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª
            min_pattern_frequency: Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰ Ù„ØªÙƒØ±Ø§Ø± Ø§Ù„Ù†Ù…Ø·
            
        Returns:
            Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…ÙƒØªØ´ÙØ©
        """
        patterns = []
        
        # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ù†ØªÙŠØ¬Ø©
        outcome_groups = {}
        for obs in observations:
            outcome = obs.get('outcome', 'unknown')
            if outcome not in outcome_groups:
                outcome_groups[outcome] = []
            outcome_groups[outcome].append(obs)
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£Ù†Ù…Ø§Ø· Ù…Ø´ØªØ±ÙƒØ©
        for outcome, group in outcome_groups.items():
            if len(group) < min_pattern_frequency:
                continue
            
            # Ø¥ÙŠØ¬Ø§Ø¯ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…Ø´ØªØ±ÙƒØ©
            common_features = self._find_common_features(group)
            
            if common_features:
                pattern = {
                    'type': 'induced',
                    'outcome': outcome,
                    'conditions': common_features,
                    'frequency': len(group),
                    'confidence': len(group) / len(observations),
                    'discovered_at': datetime.now().isoformat()
                }
                patterns.append(pattern)
                
                # Ø­ÙØ¸ Ø§Ù„Ù†Ù…Ø·
                pattern_key = f"{outcome}_{hash(str(common_features))}"
                self.learned_patterns[pattern_key] = pattern
        
        self._log_reasoning('INDUCTIVE', observations, patterns)
        return patterns
    
    def _find_common_features(
        self,
        observations: List[Dict]
    ) -> Dict[str, Any]:
        """Ø¥ÙŠØ¬Ø§Ø¯ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…Ø´ØªØ±ÙƒØ©"""
        if not observations:
            return {}
        
        # Ø¬Ù…Ø¹ ÙƒÙ„ Ø§Ù„Ù…ÙŠØ²Ø§Øª
        all_features = {}
        for obs in observations:
            features = obs.get('features', {})
            for key, value in features.items():
                if key not in all_features:
                    all_features[key] = []
                all_features[key].append(value)
        
        # Ø¥ÙŠØ¬Ø§Ø¯ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…ØªØ³Ù‚Ø©
        common = {}
        for key, values in all_features.items():
            if len(values) == len(observations):
                # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªÙ†Ø§Ø³Ù‚
                if all(isinstance(v, bool) for v in values):
                    if all(values) or not any(values):
                        common[key] = values[0]
                elif all(isinstance(v, (int, float)) for v in values):
                    mean = np.mean(values)
                    std = np.std(values)
                    if std / (abs(mean) + 1e-10) < 0.3:  # ØªØ¨Ø§ÙŠÙ† Ù…Ù†Ø®ÙØ¶
                        common[key] = {'mean': mean, 'std': std}
        
        return common
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # HYPOTHESIS GENERATION & TESTING
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def generate_hypothesis(
        self,
        observation: Dict[str, Any],
        context: Dict[str, Any]
    ) -> Hypothesis:
        """
        ØªÙˆÙ„ÙŠØ¯ ÙØ±Ø¶ÙŠØ© Ù…Ù† Ù…Ù„Ø§Ø­Ø¸Ø©
        
        Args:
            observation: Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø©
            context: Ø§Ù„Ø³ÙŠØ§Ù‚
            
        Returns:
            Ø§Ù„ÙØ±Ø¶ÙŠØ©
        """
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø©
        features = observation.get('features', {})
        
        # ØªÙˆÙ„ÙŠØ¯ ÙØ±Ø¶ÙŠØ© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…ØªØ¹Ù„Ù…Ø©
        best_match = None
        best_score = 0
        
        for pattern_key, pattern in self.learned_patterns.items():
            score = self._pattern_match_score(features, pattern['conditions'])
            if score > best_score:
                best_score = score
                best_match = pattern
        
        if best_match and best_score > 0.5:
            hypothesis = Hypothesis(
                statement=f"Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù†Ù…Ø· Ø§Ù„Ù…ØªØ¹Ù„Ù…ØŒ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©: {best_match['outcome']}",
                probability=best_score * best_match['confidence'],
                evidence_for=[f"ØªØ·Ø§Ø¨Ù‚ {best_score:.0%} Ù…Ø¹ Ø§Ù„Ù†Ù…Ø·"],
                evidence_against=[],
                test_criteria=[
                    f"Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø³Ø¹Ø± Ù„Ù…Ø¯Ø© 15 Ø¯Ù‚ÙŠÙ‚Ø©",
                    f"Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø­Ø¬Ù…",
                    f"Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ÙÙ†ÙŠØ©"
                ]
            )
        else:
            # ÙØ±Ø¶ÙŠØ© Ø§ÙØªØ±Ø§Ø¶ÙŠØ©
            hypothesis = Hypothesis(
                statement="Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù†Ù…Ø· ÙˆØ§Ø¶Ø­ - Ø§Ù„Ø³ÙˆÙ‚ ÙÙŠ Ø­Ø§Ù„Ø© ØºÙŠØ± Ù…Ø­Ø¯Ø¯Ø©",
                probability=0.5,
                evidence_for=["Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ø¥Ø´Ø§Ø±Ø§Øª Ù‚ÙˆÙŠØ©"],
                evidence_against=["ØºÙŠØ§Ø¨ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…Ø¹Ø±ÙˆÙØ©"],
                test_criteria=["Ø§Ù†ØªØ¸Ø§Ø± Ø¥Ø´Ø§Ø±Ø© ÙˆØ§Ø¶Ø­Ø©"]
            )
        
        self.hypotheses.append(hypothesis)
        return hypothesis
    
    def test_hypothesis(
        self,
        hypothesis: Hypothesis,
        new_data: Dict[str, Any]
    ) -> Hypothesis:
        """
        Ø§Ø®ØªØ¨Ø§Ø± ÙØ±Ø¶ÙŠØ© Ø¨Ø¨ÙŠØ§Ù†Ø§Øª Ø¬Ø¯ÙŠØ¯Ø©
        
        Args:
            hypothesis: Ø§Ù„ÙØ±Ø¶ÙŠØ©
            new_data: Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
            
        Returns:
            Ø§Ù„ÙØ±Ø¶ÙŠØ© Ø§Ù„Ù…Ø­Ø¯Ø«Ø©
        """
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
        tests_passed = 0
        tests_failed = 0
        
        for criterion in hypothesis.test_criteria:
            if self._evaluate_criterion(criterion, new_data):
                tests_passed += 1
                hypothesis.evidence_for.append(f"âœ“ {criterion}")
            else:
                tests_failed += 1
                hypothesis.evidence_against.append(f"âœ— {criterion}")
        
        # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ©
        total_tests = tests_passed + tests_failed
        if total_tests > 0:
            pass_rate = tests_passed / total_tests
            hypothesis.probability = hypothesis.probability * 0.7 + pass_rate * 0.3
        
        # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø­Ø§Ù„Ø©
        if hypothesis.probability > 0.7:
            hypothesis.status = "confirmed"
        elif hypothesis.probability < 0.3:
            hypothesis.status = "rejected"
        else:
            hypothesis.status = "pending"
        
        return hypothesis
    
    def _pattern_match_score(
        self,
        features: Dict,
        conditions: Dict
    ) -> float:
        """Ø­Ø³Ø§Ø¨ Ø¯Ø±Ø¬Ø© ØªØ·Ø§Ø¨Ù‚ Ø§Ù„Ù†Ù…Ø·"""
        if not conditions:
            return 0.0
        
        matched = 0
        total = len(conditions)
        
        for key, expected in conditions.items():
            if key in features:
                actual = features[key]
                if isinstance(expected, dict):
                    # Ù…Ù‚Ø§Ø±Ù†Ø© Ø±Ù‚Ù…ÙŠØ©
                    mean = expected.get('mean', 0)
                    std = expected.get('std', 1)
                    if abs(actual - mean) <= 2 * std:
                        matched += 1
                elif actual == expected:
                    matched += 1
        
        return matched / total if total > 0 else 0.0
    
    def _evaluate_criterion(self, criterion: str, data: Dict) -> bool:
        """ØªÙ‚ÙŠÙŠÙ… Ù…Ø¹ÙŠØ§Ø± Ø§Ø®ØªØ¨Ø§Ø±"""
        # ØªÙ‚ÙŠÙŠÙ… Ø¨Ø³ÙŠØ· - ÙŠÙ…ÙƒÙ† ØªÙˆØ³ÙŠØ¹Ù‡
        criterion_lower = criterion.lower()
        
        if 'Ø³Ø¹Ø±' in criterion_lower or 'price' in criterion_lower:
            return data.get('price_moved', False)
        elif 'Ø­Ø¬Ù…' in criterion_lower or 'volume' in criterion_lower:
            return data.get('volume_confirmed', False)
        elif 'Ù…Ø¤Ø´Ø±' in criterion_lower or 'indicator' in criterion_lower:
            return data.get('indicators_aligned', False)
        
        return True  # Ø§ÙØªØ±Ø§Ø¶ÙŠ
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # CAUSAL REASONING - Ø§Ù„ØªÙÙƒÙŠØ± Ø§Ù„Ø³Ø¨Ø¨ÙŠ
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def analyze_causality(
        self,
        event: Dict[str, Any],
        potential_causes: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ù„Ø§Ù‚Ø© Ø§Ù„Ø³Ø¨Ø¨ÙŠØ©
        
        Args:
            event: Ø§Ù„Ø­Ø¯Ø«
            potential_causes: Ø§Ù„Ø£Ø³Ø¨Ø§Ø¨ Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø©
            
        Returns:
            ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ø¨Ø¨ÙŠØ©
        """
        causal_analysis = {
            'event': event,
            'likely_causes': [],
            'unlikely_causes': [],
            'confidence': 0.0
        }
        
        for cause in potential_causes:
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¹Ù„Ø§Ù‚Ø© Ø§Ù„Ø²Ù…Ù†ÙŠØ©
            temporal_score = self._temporal_correlation(cause, event)
            
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¹Ù„Ø§Ù‚Ø© Ø§Ù„Ù…Ù†Ø·Ù‚ÙŠØ©
            logical_score = self._logical_correlation(cause, event)
            
            # Ø§Ù„Ø¯Ø±Ø¬Ø© Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©
            total_score = temporal_score * 0.4 + logical_score * 0.6
            
            cause_analysis = {
                'cause': cause,
                'temporal_score': temporal_score,
                'logical_score': logical_score,
                'total_score': total_score
            }
            
            if total_score > 0.5:
                causal_analysis['likely_causes'].append(cause_analysis)
            else:
                causal_analysis['unlikely_causes'].append(cause_analysis)
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø«Ù‚Ø© Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©
        if causal_analysis['likely_causes']:
            causal_analysis['confidence'] = np.mean([
                c['total_score'] for c in causal_analysis['likely_causes']
            ])
        
        return causal_analysis
    
    def _temporal_correlation(self, cause: Dict, effect: Dict) -> float:
        """Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¹Ù„Ø§Ù‚Ø© Ø§Ù„Ø²Ù…Ù†ÙŠØ©"""
        cause_time = cause.get('timestamp')
        effect_time = effect.get('timestamp')
        
        if cause_time and effect_time:
            if isinstance(cause_time, str):
                cause_time = datetime.fromisoformat(cause_time)
            if isinstance(effect_time, str):
                effect_time = datetime.fromisoformat(effect_time)
            
            # Ø§Ù„Ø³Ø¨Ø¨ ÙŠØ¬Ø¨ Ø£Ù† ÙŠØ³Ø¨Ù‚ Ø§Ù„Ù†ØªÙŠØ¬Ø©
            if cause_time < effect_time:
                time_diff = (effect_time - cause_time).total_seconds()
                # ÙƒÙ„Ù…Ø§ ÙƒØ§Ù† Ø§Ù„ÙØ§Ø±Ù‚ Ø£Ù‚Ù„ØŒ ÙƒØ§Ù†Øª Ø§Ù„Ø¹Ù„Ø§Ù‚Ø© Ø£Ù‚ÙˆÙ‰
                return max(0, 1 - time_diff / 3600)  # ØªÙ†Ø§Ù‚Øµ Ø®Ù„Ø§Ù„ Ø³Ø§Ø¹Ø©
        
        return 0.5  # Ø§ÙØªØ±Ø§Ø¶ÙŠ
    
    def _logical_correlation(self, cause: Dict, effect: Dict) -> float:
        """Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¹Ù„Ø§Ù‚Ø© Ø§Ù„Ù…Ù†Ø·Ù‚ÙŠØ©"""
        cause_type = cause.get('type', '')
        effect_type = effect.get('type', '')
        
        # Ø¹Ù„Ø§Ù‚Ø§Øª Ù…Ù†Ø·Ù‚ÙŠØ© Ù…Ø¹Ø±ÙˆÙØ©
        logical_relations = {
            ('volume_spike', 'price_move'): 0.8,
            ('news_event', 'volatility'): 0.7,
            ('whale_move', 'price_move'): 0.75,
            ('indicator_signal', 'price_move'): 0.6,
            ('market_open', 'volatility'): 0.65
        }
        
        return logical_relations.get((cause_type, effect_type), 0.3)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # REASONING CHAIN
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def build_reasoning_chain(
        self,
        initial_observation: Dict[str, Any],
        context: Dict[str, Any],
        max_steps: int = 5
    ) -> Dict[str, Any]:
        """
        Ø¨Ù†Ø§Ø¡ Ø³Ù„Ø³Ù„Ø© ØªÙÙƒÙŠØ± ÙƒØ§Ù…Ù„Ø©
        
        Args:
            initial_observation: Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø© Ø§Ù„Ø£ÙˆÙ„ÙŠØ©
            context: Ø§Ù„Ø³ÙŠØ§Ù‚
            max_steps: Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù„Ø®Ø·ÙˆØ§Øª
            
        Returns:
            Ø³Ù„Ø³Ù„Ø© Ø§Ù„ØªÙÙƒÙŠØ±
        """
        chain = {
            'steps': [],
            'final_conclusion': None,
            'confidence': 0.0,
            'reasoning_types_used': set()
        }
        
        current_state = initial_observation
        
        for step in range(max_steps):
            # 1. ØªÙˆÙ„ÙŠØ¯ ÙØ±Ø¶ÙŠØ©
            hypothesis = self.generate_hypothesis(current_state, context)
            
            # 2. Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬
            premises = [
                Premise(
                    statement=str(current_state),
                    confidence=0.8,
                    source="observation"
                )
            ]
            conclusion = self.deduce(premises, context)
            
            step_info = {
                'step': step + 1,
                'hypothesis': hypothesis.statement,
                'hypothesis_probability': hypothesis.probability,
                'conclusion': conclusion.statement if conclusion else None,
                'conclusion_confidence': conclusion.confidence if conclusion else 0
            }
            chain['steps'].append(step_info)
            
            if conclusion:
                chain['reasoning_types_used'].add(conclusion.reasoning_type.value)
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬ Ù†Ù‡Ø§Ø¦ÙŠ
            if conclusion and conclusion.confidence > 0.75:
                chain['final_conclusion'] = conclusion
                chain['confidence'] = conclusion.confidence
                break
            
            # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø­Ø§Ù„Ø© Ù„Ù„Ø®Ø·ÙˆØ© Ø§Ù„ØªØ§Ù„ÙŠØ©
            if conclusion:
                current_state = {
                    'previous': current_state,
                    'conclusion': conclusion.statement,
                    'confidence': conclusion.confidence
                }
        
        chain['reasoning_types_used'] = list(chain['reasoning_types_used'])
        return chain
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # LOGGING & HISTORY
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def _log_reasoning(
        self,
        reasoning_type: str,
        inputs: Any,
        output: Any
    ):
        """ØªØ³Ø¬ÙŠÙ„ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªÙÙƒÙŠØ±"""
        entry = {
            'timestamp': datetime.now().isoformat(),
            'type': reasoning_type,
            'inputs_summary': str(inputs)[:200],
            'output_summary': str(output)[:200]
        }
        self.reasoning_history.append(entry)
        
        # Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ø¢Ø®Ø± 1000 Ø³Ø¬Ù„
        if len(self.reasoning_history) > 1000:
            self.reasoning_history = self.reasoning_history[-1000:]
    
    def get_reasoning_summary(self) -> Dict[str, Any]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ù„Ø®Øµ Ø§Ù„ØªÙÙƒÙŠØ±"""
        return {
            'total_premises': len(self.premises),
            'total_conclusions': len(self.conclusions),
            'total_hypotheses': len(self.hypotheses),
            'learned_patterns': len(self.learned_patterns),
            'reasoning_history_size': len(self.reasoning_history),
            'confirmed_hypotheses': sum(
                1 for h in self.hypotheses if h.status == 'confirmed'
            ),
            'rejected_hypotheses': sum(
                1 for h in self.hypotheses if h.status == 'rejected'
            )
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# STANDALONE EXECUTION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == "__main__":
    # Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø­Ø±Ùƒ Ø§Ù„ØªÙÙƒÙŠØ±
    engine = ReasoningEngine()
    
    # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬
    premises = [
        Premise("RSI Ø£Ù‚Ù„ Ù…Ù† 30", 0.9, "technical_analysis"),
        Premise("Ø§Ù„Ø³Ø¹Ø± ÙÙˆÙ‚ Ø§Ù„Ù…ØªÙˆØ³Ø· 200", 0.85, "technical_analysis"),
        Premise("Ø§Ù„Ø­Ø¬Ù… Ù…ØªØ²Ø§ÙŠØ¯", 0.8, "volume_analysis")
    ]
    
    context = {
        'rsi': 25,
        'price_above_sma_200': True,
        'volume_trend': 'increasing'
    }
    
    conclusion = engine.deduce(premises, context)
    if conclusion:
        print(f"Conclusion: {conclusion.statement}")
        print(f"Confidence: {conclusion.confidence:.2%}")
    
    # Ø§Ø®ØªØ¨Ø§Ø± Ø³Ù„Ø³Ù„Ø© Ø§Ù„ØªÙÙƒÙŠØ±
    observation = {
        'features': {
            'rsi': 28,
            'macd_signal': 'bullish',
            'volume_spike': True
        }
    }
    
    chain = engine.build_reasoning_chain(observation, context)
    print(f"\nReasoning chain: {len(chain['steps'])} steps")
    print(f"Final confidence: {chain['confidence']:.2%}")
    
    # Ù…Ù„Ø®Øµ
    print(f"\nSummary: {engine.get_reasoning_summary()}")
