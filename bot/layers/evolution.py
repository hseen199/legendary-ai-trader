"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
LEGENDARY AGENT - Evolution Layer
Ø·Ø¨Ù‚Ø© Ø§Ù„ØªØ·ÙˆØ± - Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù…Ø³ØªÙ…Ø± ÙˆØ§Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø°Ø§ØªÙŠ
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import numpy as np
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
from collections import defaultdict
import json
import os
from loguru import logger


class LearningType(Enum):
    """Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„ØªØ¹Ù„Ù…"""
    TRADE_OUTCOME = "Ù†ØªÙŠØ¬Ø© ØµÙÙ‚Ø©"
    STRATEGY_PERFORMANCE = "Ø£Ø¯Ø§Ø¡ Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©"
    MARKET_PATTERN = "Ù†Ù…Ø· Ø³ÙˆÙ‚"
    ERROR_CORRECTION = "ØªØµØ­ÙŠØ­ Ø®Ø·Ø£"
    PARAMETER_TUNING = "Ø¶Ø¨Ø· Ù…Ø¹Ø§Ù…Ù„Ø§Øª"


@dataclass
class TradeLesson:
    """Ø¯Ø±Ø³ Ù…Ù† ØµÙÙ‚Ø©"""
    symbol: str
    action: str
    entry_price: float
    exit_price: float
    pnl_percent: float
    holding_time: int  # Ø¨Ø§Ù„Ø¯Ù‚Ø§Ø¦Ù‚
    market_regime: str
    features_at_entry: Dict[str, float]
    features_at_exit: Dict[str, float]
    decision_confidence: float
    actual_outcome: str  # WIN, LOSS, BREAKEVEN
    lesson: str
    timestamp: datetime = field(default_factory=datetime.now)


@dataclass
class StrategyLesson:
    """Ø¯Ø±Ø³ Ù…Ù† Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©"""
    strategy_name: str
    market_regime: str
    win_rate: float
    avg_pnl: float
    sample_size: int
    lesson: str
    adjustment: str
    timestamp: datetime = field(default_factory=datetime.now)


@dataclass
class EvolutionState:
    """Ø­Ø§Ù„Ø© Ø§Ù„ØªØ·ÙˆØ±"""
    timestamp: datetime
    total_lessons: int
    win_rate: float
    avg_pnl: float
    best_performing_regime: str
    worst_performing_regime: str
    recent_improvements: List[str]
    pending_adjustments: List[str]


class EvolutionLayer:
    """
    Ø·Ø¨Ù‚Ø© Ø§Ù„ØªØ·ÙˆØ±
    
    Ù…Ø³Ø¤ÙˆÙ„Ø© Ø¹Ù†:
    - Ø§Ù„ØªØ¹Ù„Ù… Ù…Ù† Ø§Ù„ØµÙÙ‚Ø§Øª
    - ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª
    - Ø¶Ø¨Ø· Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª
    - Ø§Ù„ØªØ·ÙˆØ± Ø§Ù„Ù…Ø³ØªÙ…Ø±
    """
    
    def __init__(self, config: Dict[str, Any] = None, data_dir: str = None):
        """
        ØªÙ‡ÙŠØ¦Ø© Ø·Ø¨Ù‚Ø© Ø§Ù„ØªØ·ÙˆØ±
        
        Args:
            config: Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø·Ø¨Ù‚Ø©
            data_dir: Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        """
        self.config = config or {}
        self.data_dir = data_dir or '/tmp/legendary_agent/evolution'
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯
        os.makedirs(self.data_dir, exist_ok=True)
        
        # Ø¯Ø±ÙˆØ³ Ø§Ù„ØµÙÙ‚Ø§Øª
        self.trade_lessons: List[TradeLesson] = []
        self.max_lessons = 10000
        
        # Ø¯Ø±ÙˆØ³ Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª
        self.strategy_lessons: List[StrategyLesson] = []
        
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡
        self.performance_stats = {
            'by_regime': defaultdict(lambda: {'wins': 0, 'losses': 0, 'total_pnl': 0}),
            'by_symbol': defaultdict(lambda: {'wins': 0, 'losses': 0, 'total_pnl': 0}),
            'by_hour': defaultdict(lambda: {'wins': 0, 'losses': 0, 'total_pnl': 0}),
            'by_confidence': defaultdict(lambda: {'wins': 0, 'losses': 0, 'total_pnl': 0})
        }
        
        # ØªØ¹Ø¯ÙŠÙ„Ø§Øª Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª
        self.parameter_adjustments = {
            'stop_loss': [],
            'take_profit': [],
            'position_size': [],
            'confidence_threshold': []
        }
        
        # Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…ÙƒØªØ´ÙØ©
        self.discovered_patterns: List[Dict] = []
        
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©
        self._load_state()
        
        logger.info("ğŸ§¬ EvolutionLayer initialized")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # LEARNING FROM TRADES
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def learn_from_trade(
        self,
        symbol: str,
        action: str,
        entry_price: float,
        exit_price: float,
        holding_time: int,
        market_regime: str,
        features_at_entry: Dict[str, float],
        features_at_exit: Dict[str, float],
        decision_confidence: float
    ) -> TradeLesson:
        """
        Ø§Ù„ØªØ¹Ù„Ù… Ù…Ù† ØµÙÙ‚Ø©
        
        Args:
            symbol: Ø±Ù…Ø² Ø§Ù„Ø¹Ù…Ù„Ø©
            action: Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡ (BUY/SELL)
            entry_price: Ø³Ø¹Ø± Ø§Ù„Ø¯Ø®ÙˆÙ„
            exit_price: Ø³Ø¹Ø± Ø§Ù„Ø®Ø±ÙˆØ¬
            holding_time: ÙˆÙ‚Øª Ø§Ù„Ø§Ø­ØªÙØ§Ø¸
            market_regime: Ù†Ø¸Ø§Ù… Ø§Ù„Ø³ÙˆÙ‚
            features_at_entry: Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø¹Ù†Ø¯ Ø§Ù„Ø¯Ø®ÙˆÙ„
            features_at_exit: Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø¹Ù†Ø¯ Ø§Ù„Ø®Ø±ÙˆØ¬
            decision_confidence: Ø«Ù‚Ø© Ø§Ù„Ù‚Ø±Ø§Ø±
            
        Returns:
            Ø§Ù„Ø¯Ø±Ø³ Ø§Ù„Ù…Ø³ØªÙØ§Ø¯
        """
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø±Ø¨Ø­/Ø§Ù„Ø®Ø³Ø§Ø±Ø©
        if action == 'BUY':
            pnl_percent = (exit_price - entry_price) / entry_price * 100
        else:
            pnl_percent = (entry_price - exit_price) / entry_price * 100
        
        # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù†ØªÙŠØ¬Ø©
        if pnl_percent > 0.5:
            outcome = 'WIN'
        elif pnl_percent < -0.5:
            outcome = 'LOSS'
        else:
            outcome = 'BREAKEVEN'
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¯Ø±Ø³
        lesson_text = self._extract_lesson(
            outcome, pnl_percent, market_regime,
            features_at_entry, decision_confidence
        )
        
        lesson = TradeLesson(
            symbol=symbol,
            action=action,
            entry_price=entry_price,
            exit_price=exit_price,
            pnl_percent=pnl_percent,
            holding_time=holding_time,
            market_regime=market_regime,
            features_at_entry=features_at_entry,
            features_at_exit=features_at_exit,
            decision_confidence=decision_confidence,
            actual_outcome=outcome,
            lesson=lesson_text
        )
        
        # Ø­ÙØ¸ Ø§Ù„Ø¯Ø±Ø³
        self.trade_lessons.append(lesson)
        if len(self.trade_lessons) > self.max_lessons:
            self.trade_lessons = self.trade_lessons[-self.max_lessons:]
        
        # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        self._update_stats(lesson)
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£Ù†Ù…Ø§Ø·
        self._discover_patterns()
        
        # Ø­ÙØ¸ Ø§Ù„Ø­Ø§Ù„Ø©
        self._save_state()
        
        logger.info(f"ğŸ“š Learned from trade: {symbol} {outcome} {pnl_percent:.2f}%")
        
        return lesson
    
    def _extract_lesson(
        self,
        outcome: str,
        pnl: float,
        regime: str,
        features: Dict,
        confidence: float
    ) -> str:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¯Ø±Ø³"""
        lessons = []
        
        if outcome == 'WIN':
            if confidence > 0.7:
                lessons.append("Ø§Ù„Ø«Ù‚Ø© Ø§Ù„Ø¹Ø§Ù„ÙŠØ© ÙƒØ§Ù†Øª Ù…Ø¨Ø±Ø±Ø©")
            if regime in ['BULL', 'STRONG_BULL']:
                lessons.append("Ø§Ù„ØªØ¯Ø§ÙˆÙ„ Ù…Ø¹ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ù†Ø§Ø¬Ø­")
        
        elif outcome == 'LOSS':
            if confidence > 0.7:
                lessons.append("âš ï¸ Ø§Ù„Ø«Ù‚Ø© Ø§Ù„Ø¹Ø§Ù„ÙŠØ© ÙƒØ§Ù†Øª Ø®Ø§Ø·Ø¦Ø© - Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ù…Ø¹Ø§ÙŠÙŠØ±")
            if regime == 'RANGING':
                lessons.append("âš ï¸ Ø§Ù„ØªØ°Ø¨Ø°Ø¨ Ø®Ø·Ø± - ØªØ¬Ù†Ø¨ Ø£Ùˆ ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø­Ø¬Ù…")
            
            rsi = features.get('rsi_14', 50)
            if rsi > 70:
                lessons.append("âš ï¸ Ø§Ù„Ø¯Ø®ÙˆÙ„ ÙÙŠ Ù…Ù†Ø·Ù‚Ø© ØªØ´Ø¨Ø¹ Ø´Ø±Ø§Ø¦ÙŠ")
            elif rsi < 30:
                lessons.append("âš ï¸ Ø§Ù„Ø¯Ø®ÙˆÙ„ ÙÙŠ Ù…Ù†Ø·Ù‚Ø© ØªØ´Ø¨Ø¹ Ø¨ÙŠØ¹ÙŠ")
        
        return " | ".join(lessons) if lessons else "ØµÙÙ‚Ø© Ø¹Ø§Ø¯ÙŠØ©"
    
    def _update_stats(self, lesson: TradeLesson) -> None:
        """ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª"""
        # Ø­Ø³Ø¨ Ø§Ù„Ù†Ø¸Ø§Ù…
        regime_stats = self.performance_stats['by_regime'][lesson.market_regime]
        if lesson.actual_outcome == 'WIN':
            regime_stats['wins'] += 1
        elif lesson.actual_outcome == 'LOSS':
            regime_stats['losses'] += 1
        regime_stats['total_pnl'] += lesson.pnl_percent
        
        # Ø­Ø³Ø¨ Ø§Ù„Ø¹Ù…Ù„Ø©
        symbol_stats = self.performance_stats['by_symbol'][lesson.symbol]
        if lesson.actual_outcome == 'WIN':
            symbol_stats['wins'] += 1
        elif lesson.actual_outcome == 'LOSS':
            symbol_stats['losses'] += 1
        symbol_stats['total_pnl'] += lesson.pnl_percent
        
        # Ø­Ø³Ø¨ Ø§Ù„Ø³Ø§Ø¹Ø©
        hour = lesson.timestamp.hour
        hour_stats = self.performance_stats['by_hour'][hour]
        if lesson.actual_outcome == 'WIN':
            hour_stats['wins'] += 1
        elif lesson.actual_outcome == 'LOSS':
            hour_stats['losses'] += 1
        hour_stats['total_pnl'] += lesson.pnl_percent
        
        # Ø­Ø³Ø¨ Ø§Ù„Ø«Ù‚Ø©
        confidence_bucket = int(lesson.decision_confidence * 10) / 10
        conf_stats = self.performance_stats['by_confidence'][confidence_bucket]
        if lesson.actual_outcome == 'WIN':
            conf_stats['wins'] += 1
        elif lesson.actual_outcome == 'LOSS':
            conf_stats['losses'] += 1
        conf_stats['total_pnl'] += lesson.pnl_percent
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # PATTERN DISCOVERY
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def _discover_patterns(self) -> None:
        """Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø£Ù†Ù…Ø§Ø·"""
        if len(self.trade_lessons) < 50:
            return
        
        recent = self.trade_lessons[-100:]
        
        # Ù†Ù…Ø·: Ø£ÙØ¶Ù„ Ù†Ø¸Ø§Ù…
        best_regime = self._find_best_regime()
        if best_regime:
            self._add_pattern({
                'type': 'best_regime',
                'regime': best_regime['regime'],
                'win_rate': best_regime['win_rate'],
                'recommendation': f"Ø§Ù„ØªØ±ÙƒÙŠØ² Ø¹Ù„Ù‰ Ø§Ù„ØªØ¯Ø§ÙˆÙ„ ÙÙŠ {best_regime['regime']}"
            })
        
        # Ù†Ù…Ø·: Ø£Ø³ÙˆØ£ Ù†Ø¸Ø§Ù…
        worst_regime = self._find_worst_regime()
        if worst_regime:
            self._add_pattern({
                'type': 'worst_regime',
                'regime': worst_regime['regime'],
                'win_rate': worst_regime['win_rate'],
                'recommendation': f"ØªØ¬Ù†Ø¨ Ø§Ù„ØªØ¯Ø§ÙˆÙ„ ÙÙŠ {worst_regime['regime']}"
            })
        
        # Ù†Ù…Ø·: Ø£ÙØ¶Ù„ Ø³Ø§Ø¹Ø©
        best_hour = self._find_best_hour()
        if best_hour:
            self._add_pattern({
                'type': 'best_hour',
                'hour': best_hour['hour'],
                'win_rate': best_hour['win_rate'],
                'recommendation': f"Ø§Ù„ØªØ¯Ø§ÙˆÙ„ ÙÙŠ Ø§Ù„Ø³Ø§Ø¹Ø© {best_hour['hour']}"
            })
    
    def _find_best_regime(self) -> Optional[Dict]:
        """Ø¥ÙŠØ¬Ø§Ø¯ Ø£ÙØ¶Ù„ Ù†Ø¸Ø§Ù…"""
        best = None
        best_rate = 0
        
        for regime, stats in self.performance_stats['by_regime'].items():
            total = stats['wins'] + stats['losses']
            if total >= 10:
                rate = stats['wins'] / total
                if rate > best_rate:
                    best_rate = rate
                    best = {'regime': regime, 'win_rate': rate}
        
        return best
    
    def _find_worst_regime(self) -> Optional[Dict]:
        """Ø¥ÙŠØ¬Ø§Ø¯ Ø£Ø³ÙˆØ£ Ù†Ø¸Ø§Ù…"""
        worst = None
        worst_rate = 1
        
        for regime, stats in self.performance_stats['by_regime'].items():
            total = stats['wins'] + stats['losses']
            if total >= 10:
                rate = stats['wins'] / total
                if rate < worst_rate:
                    worst_rate = rate
                    worst = {'regime': regime, 'win_rate': rate}
        
        return worst
    
    def _find_best_hour(self) -> Optional[Dict]:
        """Ø¥ÙŠØ¬Ø§Ø¯ Ø£ÙØ¶Ù„ Ø³Ø§Ø¹Ø©"""
        best = None
        best_rate = 0
        
        for hour, stats in self.performance_stats['by_hour'].items():
            total = stats['wins'] + stats['losses']
            if total >= 5:
                rate = stats['wins'] / total
                if rate > best_rate:
                    best_rate = rate
                    best = {'hour': hour, 'win_rate': rate}
        
        return best
    
    def _add_pattern(self, pattern: Dict) -> None:
        """Ø¥Ø¶Ø§ÙØ© Ù†Ù…Ø·"""
        pattern['discovered_at'] = datetime.now().isoformat()
        
        # ØªØ¬Ù†Ø¨ Ø§Ù„ØªÙƒØ±Ø§Ø±
        for existing in self.discovered_patterns:
            if existing.get('type') == pattern.get('type'):
                existing.update(pattern)
                return
        
        self.discovered_patterns.append(pattern)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # PARAMETER OPTIMIZATION
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def suggest_parameter_adjustments(self) -> Dict[str, Any]:
        """Ø§Ù‚ØªØ±Ø§Ø­ ØªØ¹Ø¯ÙŠÙ„Ø§Øª Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª"""
        suggestions = {}
        
        if len(self.trade_lessons) < 50:
            return suggestions
        
        recent = self.trade_lessons[-200:]
        
        # ØªØ­Ù„ÙŠÙ„ ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø©
        sl_analysis = self._analyze_stop_loss(recent)
        if sl_analysis:
            suggestions['stop_loss'] = sl_analysis
        
        # ØªØ­Ù„ÙŠÙ„ Ø¬Ù†ÙŠ Ø§Ù„Ø£Ø±Ø¨Ø§Ø­
        tp_analysis = self._analyze_take_profit(recent)
        if tp_analysis:
            suggestions['take_profit'] = tp_analysis
        
        # ØªØ­Ù„ÙŠÙ„ Ø­Ø¬Ù… Ø§Ù„Ù…Ø±ÙƒØ²
        size_analysis = self._analyze_position_size(recent)
        if size_analysis:
            suggestions['position_size'] = size_analysis
        
        # ØªØ­Ù„ÙŠÙ„ Ø¹ØªØ¨Ø© Ø§Ù„Ø«Ù‚Ø©
        conf_analysis = self._analyze_confidence_threshold(recent)
        if conf_analysis:
            suggestions['confidence_threshold'] = conf_analysis
        
        return suggestions
    
    def _analyze_stop_loss(self, lessons: List[TradeLesson]) -> Optional[Dict]:
        """ØªØ­Ù„ÙŠÙ„ ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø©"""
        losses = [l for l in lessons if l.actual_outcome == 'LOSS']
        
        if len(losses) < 10:
            return None
        
        avg_loss = np.mean([abs(l.pnl_percent) for l in losses])
        
        if avg_loss > 2.5:
            return {
                'current': 2.0,
                'suggested': 1.5,
                'reason': f"Ù…ØªÙˆØ³Ø· Ø§Ù„Ø®Ø³Ø§Ø±Ø© ({avg_loss:.1f}%) Ø£Ø¹Ù„Ù‰ Ù…Ù† Ø§Ù„Ù…ØªÙˆÙ‚Ø¹"
            }
        elif avg_loss < 1.5:
            return {
                'current': 2.0,
                'suggested': 2.5,
                'reason': "ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ø¶ÙŠÙ‚ Ø¬Ø¯Ø§Ù‹ - ÙŠÙ…ÙƒÙ† ØªÙˆØ³ÙŠØ¹Ù‡"
            }
        
        return None
    
    def _analyze_take_profit(self, lessons: List[TradeLesson]) -> Optional[Dict]:
        """ØªØ­Ù„ÙŠÙ„ Ø¬Ù†ÙŠ Ø§Ù„Ø£Ø±Ø¨Ø§Ø­"""
        wins = [l for l in lessons if l.actual_outcome == 'WIN']
        
        if len(wins) < 10:
            return None
        
        avg_win = np.mean([l.pnl_percent for l in wins])
        
        if avg_win < 1.5:
            return {
                'current': [1.5, 3.5, 6.0],
                'suggested': [1.0, 2.5, 4.0],
                'reason': "Ø¬Ù†ÙŠ Ø§Ù„Ø£Ø±Ø¨Ø§Ø­ Ù…Ø¨ÙƒØ±Ø§Ù‹ Ù„ØªØ£Ù…ÙŠÙ† Ø§Ù„Ù…ÙƒØ§Ø³Ø¨"
            }
        
        return None
    
    def _analyze_position_size(self, lessons: List[TradeLesson]) -> Optional[Dict]:
        """ØªØ­Ù„ÙŠÙ„ Ø­Ø¬Ù… Ø§Ù„Ù…Ø±ÙƒØ²"""
        # Ø­Ø³Ø§Ø¨ Ù†Ø³Ø¨Ø© Ø§Ù„ÙÙˆØ² Ø­Ø³Ø¨ Ø§Ù„Ø«Ù‚Ø©
        high_conf = [l for l in lessons if l.decision_confidence > 0.7]
        low_conf = [l for l in lessons if l.decision_confidence < 0.5]
        
        if len(high_conf) >= 10 and len(low_conf) >= 10:
            high_win_rate = len([l for l in high_conf if l.actual_outcome == 'WIN']) / len(high_conf)
            low_win_rate = len([l for l in low_conf if l.actual_outcome == 'WIN']) / len(low_conf)
            
            if high_win_rate > low_win_rate + 0.15:
                return {
                    'suggestion': 'Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø­Ø¬Ù… ÙÙŠ Ø§Ù„ØµÙÙ‚Ø§Øª Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø«Ù‚Ø©',
                    'high_conf_win_rate': high_win_rate,
                    'low_conf_win_rate': low_win_rate
                }
        
        return None
    
    def _analyze_confidence_threshold(self, lessons: List[TradeLesson]) -> Optional[Dict]:
        """ØªØ­Ù„ÙŠÙ„ Ø¹ØªØ¨Ø© Ø§Ù„Ø«Ù‚Ø©"""
        by_confidence = defaultdict(list)
        
        for lesson in lessons:
            bucket = round(lesson.decision_confidence, 1)
            by_confidence[bucket].append(lesson)
        
        # Ø¥ÙŠØ¬Ø§Ø¯ Ø£ÙØ¶Ù„ Ø¹ØªØ¨Ø©
        best_threshold = 0.5
        best_performance = 0
        
        for threshold in np.arange(0.4, 0.8, 0.1):
            above = [l for l in lessons if l.decision_confidence >= threshold]
            if len(above) >= 20:
                wins = len([l for l in above if l.actual_outcome == 'WIN'])
                performance = wins / len(above)
                if performance > best_performance:
                    best_performance = performance
                    best_threshold = threshold
        
        if best_threshold != 0.5:
            return {
                'current': 0.5,
                'suggested': best_threshold,
                'expected_win_rate': best_performance,
                'reason': f"ØªØ­Ø³ÙŠÙ† Ù†Ø³Ø¨Ø© Ø§Ù„ÙÙˆØ² Ø¥Ù„Ù‰ {best_performance:.1%}"
            }
        
        return None
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # EVOLUTION STATE
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def get_evolution_state(self) -> EvolutionState:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø­Ø§Ù„Ø© Ø§Ù„ØªØ·ÙˆØ±"""
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        total_trades = len(self.trade_lessons)
        wins = len([l for l in self.trade_lessons if l.actual_outcome == 'WIN'])
        win_rate = wins / total_trades if total_trades > 0 else 0
        avg_pnl = np.mean([l.pnl_percent for l in self.trade_lessons]) if self.trade_lessons else 0
        
        # Ø£ÙØ¶Ù„ ÙˆØ£Ø³ÙˆØ£ Ù†Ø¸Ø§Ù…
        best_regime = self._find_best_regime()
        worst_regime = self._find_worst_regime()
        
        # Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ù„Ø£Ø®ÙŠØ±Ø©
        recent_improvements = []
        for pattern in self.discovered_patterns[-5:]:
            recent_improvements.append(pattern.get('recommendation', ''))
        
        # Ø§Ù„ØªØ¹Ø¯ÙŠÙ„Ø§Øª Ø§Ù„Ù…Ø¹Ù„Ù‚Ø©
        pending = self.suggest_parameter_adjustments()
        pending_adjustments = [f"{k}: {v.get('reason', '')}" for k, v in pending.items()]
        
        return EvolutionState(
            timestamp=datetime.now(),
            total_lessons=total_trades,
            win_rate=win_rate,
            avg_pnl=avg_pnl,
            best_performing_regime=best_regime['regime'] if best_regime else 'N/A',
            worst_performing_regime=worst_regime['regime'] if worst_regime else 'N/A',
            recent_improvements=recent_improvements,
            pending_adjustments=pending_adjustments
        )
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # PERSISTENCE
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def _save_state(self) -> None:
        """Ø­ÙØ¸ Ø§Ù„Ø­Ø§Ù„Ø©"""
        try:
            state = {
                'trade_lessons': [
                    {
                        'symbol': l.symbol,
                        'action': l.action,
                        'entry_price': l.entry_price,
                        'exit_price': l.exit_price,
                        'pnl_percent': l.pnl_percent,
                        'holding_time': l.holding_time,
                        'market_regime': l.market_regime,
                        'decision_confidence': l.decision_confidence,
                        'actual_outcome': l.actual_outcome,
                        'lesson': l.lesson,
                        'timestamp': l.timestamp.isoformat()
                    }
                    for l in self.trade_lessons[-1000:]  # Ø¢Ø®Ø± 1000 ÙÙ‚Ø·
                ],
                'performance_stats': {
                    k: dict(v) for k, v in self.performance_stats.items()
                },
                'discovered_patterns': self.discovered_patterns
            }
            
            path = os.path.join(self.data_dir, 'evolution_state.json')
            with open(path, 'w') as f:
                json.dump(state, f, indent=2, default=str)
                
        except Exception as e:
            logger.error(f"Failed to save evolution state: {e}")
    
    def _load_state(self) -> None:
        """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø­Ø§Ù„Ø©"""
        try:
            path = os.path.join(self.data_dir, 'evolution_state.json')
            if os.path.exists(path):
                with open(path, 'r') as f:
                    state = json.load(f)
                
                # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø£Ù†Ù…Ø§Ø·
                self.discovered_patterns = state.get('discovered_patterns', [])
                
                # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
                for key, value in state.get('performance_stats', {}).items():
                    if key in self.performance_stats:
                        for k, v in value.items():
                            self.performance_stats[key][k] = v
                
                logger.info(f"ğŸ“‚ Loaded evolution state with {len(self.discovered_patterns)} patterns")
                
        except Exception as e:
            logger.warning(f"Could not load evolution state: {e}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # STATUS
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def get_status(self) -> Dict[str, Any]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø­Ø§Ù„Ø© Ø§Ù„Ø·Ø¨Ù‚Ø©"""
        state = self.get_evolution_state()
        return {
            'total_lessons': state.total_lessons,
            'win_rate': f"{state.win_rate:.1%}",
            'avg_pnl': f"{state.avg_pnl:.2f}%",
            'best_regime': state.best_performing_regime,
            'worst_regime': state.worst_performing_regime,
            'patterns_discovered': len(self.discovered_patterns),
            'pending_adjustments': len(state.pending_adjustments)
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# STANDALONE EXECUTION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == "__main__":
    # Ø§Ø®ØªØ¨Ø§Ø± Ø·Ø¨Ù‚Ø© Ø§Ù„ØªØ·ÙˆØ±
    evolution = EvolutionLayer()
    
    # Ù…Ø­Ø§ÙƒØ§Ø© ØµÙÙ‚Ø§Øª
    import random
    
    regimes = ['BULL', 'BEAR', 'RANGING', 'STRONG_BULL']
    symbols = ['BTCUSDT', 'ETHUSDT', 'BNBUSDT']
    
    for i in range(100):
        regime = random.choice(regimes)
        symbol = random.choice(symbols)
        
        # ØµÙÙ‚Ø§Øª ÙÙŠ BULL Ø£ÙØ¶Ù„
        if regime in ['BULL', 'STRONG_BULL']:
            pnl_base = 1.5
        else:
            pnl_base = -0.5
        
        pnl = pnl_base + random.uniform(-2, 2)
        
        lesson = evolution.learn_from_trade(
            symbol=symbol,
            action='BUY',
            entry_price=50000,
            exit_price=50000 * (1 + pnl/100),
            holding_time=random.randint(30, 240),
            market_regime=regime,
            features_at_entry={'rsi_14': random.uniform(30, 70)},
            features_at_exit={'rsi_14': random.uniform(30, 70)},
            decision_confidence=random.uniform(0.4, 0.9)
        )
    
    # Ø¹Ø±Ø¶ Ø­Ø§Ù„Ø© Ø§Ù„ØªØ·ÙˆØ±
    state = evolution.get_evolution_state()
    
    print("ğŸ§¬ Evolution State:")
    print(f"Total Lessons: {state.total_lessons}")
    print(f"Win Rate: {state.win_rate:.1%}")
    print(f"Avg PnL: {state.avg_pnl:.2f}%")
    print(f"Best Regime: {state.best_performing_regime}")
    print(f"Worst Regime: {state.worst_performing_regime}")
    
    print("\nğŸ“ˆ Recent Improvements:")
    for imp in state.recent_improvements:
        print(f"  - {imp}")
    
    print("\nâš™ï¸ Pending Adjustments:")
    for adj in state.pending_adjustments:
        print(f"  - {adj}")
    
    print("\nğŸ” Discovered Patterns:")
    for pattern in evolution.discovered_patterns:
        print(f"  - {pattern.get('type')}: {pattern.get('recommendation')}")
