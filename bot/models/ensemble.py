"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
LEGENDARY AGENT - Ensemble Model
Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø¯Ù…Ø¬ Ø§Ù„Ø°ÙƒÙŠ Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from typing import Dict, List, Optional, Tuple, Any
from datetime import datetime
from loguru import logger

from .base_model import BaseModel
from .tft_model import TFTModel
from .lstm_attention import LSTMAttentionModel
from .market_regime import MarketRegimeClassifier


class MetaLearner(nn.Module):
    """
    Ø§Ù„Ù…ØªØ¹Ù„Ù… Ø§Ù„ÙÙˆÙ‚ÙŠ Ù„Ø¯Ù…Ø¬ ØªÙ†Ø¨Ø¤Ø§Øª Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
    """
    
    def __init__(
        self,
        num_models: int,
        num_classes: int = 3,
        hidden_dim: int = 32
    ):
        """
        ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…ØªØ¹Ù„Ù… Ø§Ù„ÙÙˆÙ‚ÙŠ
        
        Args:
            num_models: Ø¹Ø¯Ø¯ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
            num_classes: Ø¹Ø¯Ø¯ Ø§Ù„ÙØ¦Ø§Øª
            hidden_dim: Ø­Ø¬Ù… Ø§Ù„Ø·Ø¨Ù‚Ø© Ø§Ù„Ù…Ø®ÙÙŠØ©
        """
        super().__init__()
        
        # Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª: Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª ÙƒÙ„ Ù†Ù…ÙˆØ°Ø¬ + Ø«Ù‚Ø© + Ø­Ø§Ù„Ø© Ø§Ù„Ø³ÙˆÙ‚
        input_dim = num_models * num_classes + num_models + 7  # 7 Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ø³ÙˆÙ‚
        
        self.network = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim, num_classes)
        )
        
        # Ø·Ø¨Ù‚Ø© Ø§Ù„Ø«Ù‚Ø©
        self.confidence_net = nn.Sequential(
            nn.Linear(input_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Linear(hidden_dim // 2, 1),
            nn.Sigmoid()
        )
    
    def forward(
        self, 
        model_probs: torch.Tensor,
        model_confidences: torch.Tensor,
        regime_probs: torch.Tensor
    ) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        Ø§Ù„ØªÙ…Ø±ÙŠØ± Ø§Ù„Ø£Ù…Ø§Ù…ÙŠ
        
        Args:
            model_probs: Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ [batch, num_models * num_classes]
            model_confidences: Ø«Ù‚Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ [batch, num_models]
            regime_probs: Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª Ø­Ø§Ù„Ø© Ø§Ù„Ø³ÙˆÙ‚ [batch, 7]
            
        Returns:
            (logits, confidence)
        """
        # Ø¯Ù…Ø¬ Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª
        combined = torch.cat([model_probs, model_confidences, regime_probs], dim=1)
        
        logits = self.network(combined)
        confidence = self.confidence_net(combined)
        
        return logits, confidence


class EnsembleModel(BaseModel):
    """
    Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø¯Ù…Ø¬ Ø§Ù„Ø°ÙƒÙŠ
    
    ÙŠØ¬Ù…Ø¹ Ø¨ÙŠÙ†:
    - TFT Ù„Ù„ØªÙ†Ø¨Ø¤ Ø§Ù„Ø²Ù…Ù†ÙŠ
    - LSTM+Attention Ù„Ù„Ø£Ù†Ù…Ø§Ø·
    - Market Regime Ù„Ù„Ø³ÙŠØ§Ù‚
    - Meta Learner Ù„Ù„Ø¯Ù…Ø¬ Ø§Ù„Ø°ÙƒÙŠ
    """
    
    def __init__(
        self,
        input_dim: int,
        hidden_dim: int = 128,
        sequence_length: int = 60,
        output_dim: int = 3,
        config: Optional[Dict] = None
    ):
        """
        ØªÙ‡ÙŠØ¦Ø© Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø¯Ù…Ø¬
        
        Args:
            input_dim: Ø¹Ø¯Ø¯ Ø§Ù„Ù…ÙŠØ²Ø§Øª
            hidden_dim: Ø­Ø¬Ù… Ø§Ù„Ø·Ø¨Ù‚Ø© Ø§Ù„Ù…Ø®ÙÙŠØ©
            sequence_length: Ø·ÙˆÙ„ Ø§Ù„ØªØ³Ù„Ø³Ù„
            output_dim: Ø¹Ø¯Ø¯ Ø§Ù„ÙØ¦Ø§Øª
            config: Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©
        """
        config = config or {}
        config.update({
            'input_dim': input_dim,
            'hidden_dim': hidden_dim,
            'sequence_length': sequence_length,
            'output_dim': output_dim
        })
        
        super().__init__("Ensemble", config)
        
        self.input_dim = input_dim
        self.hidden_dim = hidden_dim
        self.sequence_length = sequence_length
        self.output_dim = output_dim
        
        # Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ÙØ±Ø¹ÙŠØ©
        self.tft = TFTModel(
            input_dim=input_dim,
            hidden_dim=hidden_dim,
            num_heads=4,
            num_encoder_layers=2,
            sequence_length=sequence_length,
            output_dim=output_dim
        )
        
        self.lstm = LSTMAttentionModel(
            input_dim=input_dim,
            hidden_dim=hidden_dim,
            num_layers=2,
            num_heads=4,
            sequence_length=sequence_length,
            output_dim=output_dim
        )
        
        self.regime_classifier = MarketRegimeClassifier(
            input_dim=input_dim,
            hidden_dim=hidden_dim // 2,
            num_regimes=7,
            sequence_length=sequence_length
        )
        
        # Ø§Ù„Ù…ØªØ¹Ù„Ù… Ø§Ù„ÙÙˆÙ‚ÙŠ
        self.meta_learner = MetaLearner(
            num_models=2,  # TFT + LSTM
            num_classes=output_dim,
            hidden_dim=64
        )
        
        # Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ (Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªØ¹Ù„Ù…)
        self.model_weights = nn.Parameter(torch.ones(2) / 2)
        
        # ØªØ§Ø±ÙŠØ® Ø§Ù„Ø£Ø¯Ø§Ø¡
        self.performance_history: Dict[str, List[float]] = {
            'tft': [],
            'lstm': [],
            'ensemble': []
        }
        
        logger.info(f"ğŸ§  Ensemble Model initialized with {self._count_total_params():,} total parameters")
    
    def _count_total_params(self) -> int:
        """Ø¹Ø¯ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª"""
        total = 0
        total += sum(p.numel() for p in self.tft.parameters())
        total += sum(p.numel() for p in self.lstm.parameters())
        total += sum(p.numel() for p in self.regime_classifier.parameters())
        total += sum(p.numel() for p in self.meta_learner.parameters())
        total += self.model_weights.numel()
        return total
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        Ø§Ù„ØªÙ…Ø±ÙŠØ± Ø§Ù„Ø£Ù…Ø§Ù…ÙŠ
        
        Args:
            x: Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª [batch, sequence, features]
            
        Returns:
            Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª [batch, output_dim]
        """
        # ØªÙ†Ø¨Ø¤Ø§Øª Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ÙØ±Ø¹ÙŠØ©
        tft_logits = self.tft(x)
        lstm_logits = self.lstm(x)
        regime_logits, regime_conf = self.regime_classifier.forward_with_confidence(x)
        
        # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª
        tft_probs = F.softmax(tft_logits, dim=-1)
        lstm_probs = F.softmax(lstm_logits, dim=-1)
        regime_probs = F.softmax(regime_logits, dim=-1)
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø«Ù‚Ø©
        tft_conf = tft_probs.max(dim=-1)[0].unsqueeze(-1)
        lstm_conf = lstm_probs.max(dim=-1)[0].unsqueeze(-1)
        
        # Ø¯Ù…Ø¬ Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª
        model_probs = torch.cat([tft_probs, lstm_probs], dim=-1)
        model_confs = torch.cat([tft_conf, lstm_conf], dim=-1)
        
        # Ø§Ù„Ù…ØªØ¹Ù„Ù… Ø§Ù„ÙÙˆÙ‚ÙŠ
        final_logits, _ = self.meta_learner(model_probs, model_confs, regime_probs)
        
        return final_logits
    
    def predict(self, x: np.ndarray) -> Dict[str, Any]:
        """
        Ø§Ù„ØªÙ†Ø¨Ø¤ Ø§Ù„Ø´Ø§Ù…Ù„
        
        Args:
            x: Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª
            
        Returns:
            Ù‚Ø§Ù…ÙˆØ³ Ø´Ø§Ù…Ù„ Ø¨Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª
        """
        self.eval()
        
        if x.ndim == 2:
            x = x[np.newaxis, :, :]
        
        with torch.no_grad():
            x_tensor = torch.FloatTensor(x).to(self.device)
            
            # ØªÙ†Ø¨Ø¤Ø§Øª ÙØ±Ø¯ÙŠØ©
            tft_pred = self.tft.predict(x)
            lstm_pred = self.lstm.predict(x)
            regime_pred = self.regime_classifier.predict(x)
            
            # Ø§Ù„ØªÙ†Ø¨Ø¤ Ø§Ù„Ù…Ø¯Ù…Ø¬
            final_logits = self.forward(x_tensor)
            final_probs = F.softmax(final_logits, dim=-1)
            final_preds = torch.argmax(final_probs, dim=-1)
        
        final_probs_np = final_probs.cpu().numpy()
        final_preds_np = final_preds.cpu().numpy()
        
        action_map = {0: 'BUY', 1: 'SELL', 2: 'HOLD'}
        
        results = []
        for i in range(len(final_preds_np)):
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø§ØªÙØ§Ù‚ Ø¨ÙŠÙ† Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
            models_agree = (
                tft_pred['action'] == lstm_pred['action'] == action_map[final_preds_np[i]]
            )
            
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø«Ù‚Ø© Ø§Ù„Ù…Ø±ÙƒØ¨Ø©
            composite_confidence = (
                tft_pred['confidence'] * 0.35 +
                lstm_pred['confidence'] * 0.35 +
                float(final_probs_np[i].max()) * 0.30
            )
            
            # ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø«Ù‚Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø­Ø§Ù„Ø© Ø§Ù„Ø³ÙˆÙ‚
            regime_adjustment = self._get_regime_adjustment(regime_pred)
            adjusted_confidence = composite_confidence * regime_adjustment
            
            results.append({
                'action': action_map[final_preds_np[i]],
                'confidence': float(adjusted_confidence),
                'probabilities': {
                    'BUY': float(final_probs_np[i, 0]),
                    'SELL': float(final_probs_np[i, 1]),
                    'HOLD': float(final_probs_np[i, 2])
                },
                'models_agree': models_agree,
                'individual_predictions': {
                    'tft': tft_pred,
                    'lstm': lstm_pred
                },
                'market_regime': regime_pred,
                'reasoning': self._generate_reasoning(
                    action_map[final_preds_np[i]],
                    tft_pred,
                    lstm_pred,
                    regime_pred,
                    models_agree
                ),
                'risk_assessment': self._assess_risk(
                    action_map[final_preds_np[i]],
                    adjusted_confidence,
                    regime_pred
                )
            })
        
        return results[0] if len(results) == 1 else results
    
    def _get_regime_adjustment(self, regime_pred: Dict) -> float:
        """
        Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø¹Ø§Ù…Ù„ ØªØ¹Ø¯ÙŠÙ„ Ø­Ø³Ø¨ Ø­Ø§Ù„Ø© Ø§Ù„Ø³ÙˆÙ‚
        
        Args:
            regime_pred: ØªÙ†Ø¨Ø¤ Ø­Ø§Ù„Ø© Ø§Ù„Ø³ÙˆÙ‚
            
        Returns:
            Ù…Ø¹Ø§Ù…Ù„ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„
        """
        regime = regime_pred.get('regime', 'NEUTRAL')
        
        adjustments = {
            'STRONG_BULLISH': 1.1,
            'BULLISH': 1.05,
            'NEUTRAL': 1.0,
            'BEARISH': 0.9,
            'STRONG_BEARISH': 0.8,
            'HIGH_VOLATILITY': 0.85,
            'LOW_VOLATILITY': 0.95
        }
        
        return adjustments.get(regime, 1.0)
    
    def _generate_reasoning(
        self,
        action: str,
        tft_pred: Dict,
        lstm_pred: Dict,
        regime_pred: Dict,
        models_agree: bool
    ) -> str:
        """
        ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªØ¨Ø±ÙŠØ± Ø§Ù„Ù…Ù†Ø·Ù‚ÙŠ Ù„Ù„Ù‚Ø±Ø§Ø±
        
        Args:
            action: Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ù„Ù…Ù‚ØªØ±Ø­
            tft_pred: ØªÙ†Ø¨Ø¤ TFT
            lstm_pred: ØªÙ†Ø¨Ø¤ LSTM
            regime_pred: Ø­Ø§Ù„Ø© Ø§Ù„Ø³ÙˆÙ‚
            models_agree: Ù‡Ù„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ù…ØªÙÙ‚Ø©
            
        Returns:
            Ù†Øµ Ø§Ù„ØªØ¨Ø±ÙŠØ±
        """
        reasoning_parts = []
        
        # Ø­Ø§Ù„Ø© Ø§Ù„Ø³ÙˆÙ‚
        regime = regime_pred.get('regime', 'NEUTRAL')
        reasoning_parts.append(f"Ø­Ø§Ù„Ø© Ø§Ù„Ø³ÙˆÙ‚: {regime}")
        
        # Ø§ØªÙØ§Ù‚ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
        if models_agree:
            reasoning_parts.append("Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ù…ØªÙÙ‚Ø© Ø¹Ù„Ù‰ Ù‡Ø°Ø§ Ø§Ù„Ù‚Ø±Ø§Ø±")
        else:
            reasoning_parts.append(
                f"TFT ÙŠÙ‚ØªØ±Ø­ {tft_pred['action']} ({tft_pred['confidence']:.1%}), "
                f"LSTM ÙŠÙ‚ØªØ±Ø­ {lstm_pred['action']} ({lstm_pred['confidence']:.1%})"
            )
        
        # ØªÙˆØµÙŠØ© Ø­Ø§Ù„Ø© Ø§Ù„Ø³ÙˆÙ‚
        if 'trading_recommendation' in regime_pred:
            rec = regime_pred['trading_recommendation']
            reasoning_parts.append(f"ØªÙˆØµÙŠØ© Ø§Ù„Ø³ÙˆÙ‚: {rec.get('description', '')}")
        
        # Ø§Ù„ØªØ¨Ø±ÙŠØ± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
        if action == 'BUY':
            reasoning_parts.append("Ø¥Ø´Ø§Ø±Ø§Øª Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ© ØªØ¯Ø¹Ù… Ø§Ù„Ø´Ø±Ø§Ø¡")
        elif action == 'SELL':
            reasoning_parts.append("Ø¥Ø´Ø§Ø±Ø§Øª Ø³Ù„Ø¨ÙŠØ© ØªØ¯Ø¹Ù… Ø§Ù„Ø¨ÙŠØ¹")
        else:
            reasoning_parts.append("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¥Ø´Ø§Ø±Ø© ÙˆØ§Ø¶Ø­Ø© - Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± Ø£ÙØ¶Ù„")
        
        return " | ".join(reasoning_parts)
    
    def _assess_risk(
        self,
        action: str,
        confidence: float,
        regime_pred: Dict
    ) -> Dict[str, Any]:
        """
        ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…Ø®Ø§Ø·Ø±
        
        Args:
            action: Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡
            confidence: Ø§Ù„Ø«Ù‚Ø©
            regime_pred: Ø­Ø§Ù„Ø© Ø§Ù„Ø³ÙˆÙ‚
            
        Returns:
            ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…Ø®Ø§Ø·Ø±
        """
        regime = regime_pred.get('regime', 'NEUTRAL')
        
        # Ø­Ø³Ø§Ø¨ Ø¯Ø±Ø¬Ø© Ø§Ù„Ù…Ø®Ø§Ø·Ø±
        base_risk = 0.5
        
        # ØªØ¹Ø¯ÙŠÙ„ Ø­Ø³Ø¨ Ø§Ù„Ø«Ù‚Ø©
        if confidence > 0.8:
            base_risk -= 0.2
        elif confidence < 0.5:
            base_risk += 0.2
        
        # ØªØ¹Ø¯ÙŠÙ„ Ø­Ø³Ø¨ Ø­Ø§Ù„Ø© Ø§Ù„Ø³ÙˆÙ‚
        regime_risks = {
            'STRONG_BULLISH': -0.1,
            'BULLISH': -0.05,
            'NEUTRAL': 0,
            'BEARISH': 0.1,
            'STRONG_BEARISH': 0.2,
            'HIGH_VOLATILITY': 0.25,
            'LOW_VOLATILITY': -0.05
        }
        base_risk += regime_risks.get(regime, 0)
        
        # ØªØ¹Ø¯ÙŠÙ„ Ø­Ø³Ø¨ Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡
        if action == 'HOLD':
            base_risk -= 0.1
        
        risk_score = max(0, min(1, base_risk))
        
        # ØªØ­Ø¯ÙŠØ¯ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ù…Ø®Ø§Ø·Ø±
        if risk_score < 0.3:
            risk_level = 'LOW'
        elif risk_score < 0.5:
            risk_level = 'MEDIUM'
        elif risk_score < 0.7:
            risk_level = 'HIGH'
        else:
            risk_level = 'EXTREME'
        
        return {
            'score': risk_score,
            'level': risk_level,
            'factors': {
                'confidence': confidence,
                'market_regime': regime,
                'action': action
            },
            'recommendation': self._get_risk_recommendation(risk_level, action)
        }
    
    def _get_risk_recommendation(self, risk_level: str, action: str) -> str:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªÙˆØµÙŠØ© Ø§Ù„Ù…Ø®Ø§Ø·Ø±"""
        if risk_level == 'EXTREME':
            return "Ù…Ø®Ø§Ø·Ø± Ø¹Ø§Ù„ÙŠØ© Ø¬Ø¯Ø§Ù‹ - ØªØ¬Ù†Ø¨ Ø§Ù„ØªØ¯Ø§ÙˆÙ„ Ø£Ùˆ Ø§Ø³ØªØ®Ø¯Ù… Ø­Ø¬Ù… ØµØºÙŠØ± Ø¬Ø¯Ø§Ù‹"
        elif risk_level == 'HIGH':
            return "Ù…Ø®Ø§Ø·Ø± Ø¹Ø§Ù„ÙŠØ© - Ù‚Ù„Ù„ Ø­Ø¬Ù… Ø§Ù„ØµÙÙ‚Ø© ÙˆØ§Ø³ØªØ®Ø¯Ù… ÙˆÙ‚Ù Ø®Ø³Ø§Ø±Ø© Ø¶ÙŠÙ‚"
        elif risk_level == 'MEDIUM':
            return "Ù…Ø®Ø§Ø·Ø± Ù…ØªÙˆØ³Ø·Ø© - Ø§Ù„ØªØ²Ù… Ø¨Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø®Ø§Ø·Ø± Ø§Ù„Ù…Ø¹ØªØ§Ø¯Ø©"
        else:
            return "Ù…Ø®Ø§Ø·Ø± Ù…Ù†Ø®ÙØ¶Ø© - ÙŠÙ…ÙƒÙ† Ø²ÙŠØ§Ø¯Ø© Ø­Ø¬Ù… Ø§Ù„ØµÙÙ‚Ø© Ù‚Ù„ÙŠÙ„Ø§Ù‹"
    
    def get_input_shape(self) -> Tuple[int, int]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø´ÙƒÙ„ Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª"""
        return (self.sequence_length, self.input_dim)
    
    def _get_loss_function(self) -> nn.Module:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¯Ø§Ù„Ø© Ø§Ù„Ø®Ø³Ø§Ø±Ø©"""
        return nn.CrossEntropyLoss()
    
    def update_performance(self, model_name: str, accuracy: float) -> None:
        """
        ØªØ­Ø¯ÙŠØ« ØªØ§Ø±ÙŠØ® Ø§Ù„Ø£Ø¯Ø§Ø¡
        
        Args:
            model_name: Ø§Ø³Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            accuracy: Ø§Ù„Ø¯Ù‚Ø©
        """
        if model_name in self.performance_history:
            self.performance_history[model_name].append(accuracy)
            # Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ø¢Ø®Ø± 100 Ù‚ÙŠÙ…Ø© ÙÙ‚Ø·
            if len(self.performance_history[model_name]) > 100:
                self.performance_history[model_name] = self.performance_history[model_name][-100:]
    
    def get_model_weights(self) -> Dict[str, float]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø­Ø§Ù„ÙŠØ©"""
        weights = F.softmax(self.model_weights, dim=0)
        return {
            'tft': float(weights[0]),
            'lstm': float(weights[1])
        }
    
    def save_all(self, save_dir: str) -> None:
        """Ø­ÙØ¸ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬"""
        import os
        os.makedirs(save_dir, exist_ok=True)
        
        self.tft.save(os.path.join(save_dir, "tft.pt"))
        self.lstm.save(os.path.join(save_dir, "lstm.pt"))
        self.regime_classifier.save(os.path.join(save_dir, "regime.pt"))
        self.save(os.path.join(save_dir, "ensemble.pt"))
        
        logger.info(f"âœ… All models saved to {save_dir}")
    
    def load_all(self, save_dir: str) -> None:
        """ØªØ­Ù…ÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬"""
        import os
        
        self.tft.load(os.path.join(save_dir, "tft.pt"))
        self.lstm.load(os.path.join(save_dir, "lstm.pt"))
        self.regime_classifier.load(os.path.join(save_dir, "regime.pt"))
        self.load(os.path.join(save_dir, "ensemble.pt"))
        
        logger.info(f"âœ… All models loaded from {save_dir}")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# STANDALONE EXECUTION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == "__main__":
    # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    model = EnsembleModel(
        input_dim=50,
        hidden_dim=64,
        sequence_length=60,
        output_dim=3
    )
    
    # Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¬Ø±ÙŠØ¨ÙŠØ©
    x = np.random.randn(2, 60, 50).astype(np.float32)
    
    # ØªÙ†Ø¨Ø¤
    result = model.predict(x)
    print(f"Ensemble Prediction:")
    print(f"  Action: {result['action']}")
    print(f"  Confidence: {result['confidence']:.2%}")
    print(f"  Models Agree: {result['models_agree']}")
    print(f"  Risk Level: {result['risk_assessment']['level']}")
    print(f"\nReasoning: {result['reasoning']}")
    
    # Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
    print(f"\nModel weights: {model.get_model_weights()}")
